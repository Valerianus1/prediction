---
title: "machine learning"
author: "Leonardo Solaro"
date: "27/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Intro

Well, that was underwhelming. I ran two simple ML algorithms (KNN and RF), and even though they differed a lot on their predictions, apparently the one I chose to use as an answer got me 100% without any fine-tuning...

```{r}
library(dplyr)
library(data.table)
library(caret)

set.seed(123)
```

## Loading data and preprocessing:

```{r}
train <- read.csv("pml-training.csv")[, -1]
test <- read.csv("pml-testing.csv")[, -1]

na <- colSums(is.na(train)) 
na <- sapply(train, function(x) sum(is.na(x)))
na_rm <- names(na[na>20]) # remove variables with lots of NA (one hundred of them)

train <- train[, -which(names(train) %in% na_rm)]
test <- test[, -which(names(test) %in% na_rm)]
```

## Modelling:

The first model is not run because it's taking me time to prepare the html file

```{r}
train(classe ~ ., data = train, method = "knn", 
             tuneGrid = expand.grid(k=1:20),
             trControl = trainControl(method = "LGOCV", p = 0.8, number = 1,
                                      savePredictions = T))

mod2 <- train(classe ~ ., data = train, method = "rf", 
              #tuneGrid = expand.grid(k=1:20, .mtry=5),
              trControl = trainControl(method = "repeatedcv", number = 5,
                                       savePredictions = T, allowParallel = TRUE))

pred1 <- predict(mod1, test)
pred2 <- predict(mod2, test)
pred1==pred2 # to see how the predictions compared. I ended up submitting the answers from the RF model
```

# My predictions:

```{r}
pred2
```

I had considered trying PCA for dimensionality reduction, but I guess it wasn't necessary

```{r}
#preproc_pca <-  preProcess(train, method="pca", thresh=0.99)
#trainpca <- predict(preproc_pca, subset(train, select = -c(classe)))

#modelPCA<- train(x = trainpca, y = train$classe, method="glm")
#modelPCAresult <- confusionMatrix(new_testing$problem_id,predict(model_with_PCA, newdata=testPC))
#modelPCAresult -->
```